wandb:
  log: True
  entity: "dynanlp" # あなたのW&Bエンティティ名
  project: "leaderboard_test" # プロジェクト名
  run_name: 'your_run_name' # 実行名を適宜変更

github_version: v2.0.0

testmode: false

api: false  # OpenAI APIを使用しないように設定

model:
  use_wandb_artifacts: false
  artifacts_path: ""
  pretrained_model_name_or_path: 'meta-llama/Llama-3.3-70B-Instruct'  # 使用したいモデルに変更
  trust_remote_code: true
  device_map: "auto"
  load_in_8bit: false
  load_in_4bit: false

generator:
  do_sample: false
  temperature: 0

tokenizer:
  use_wandb_artifacts: false
  artifacts_path: ""
  pretrained_model_name_or_path: "meta-llama/Llama-3.3-70B-Instruct"  # 使用したいモデルに変更
  use_fast: true

max_seq_length: 1024
dataset_artifact: "wandb-japan/llm-leaderboard/jaster:v11"
dataset_dir: "/jaster/1.2.6/evaluation/test"
target_dataset: "all"
log_dir: "./logs"
torch_dtype: "bf16"
custom_prompt_template: null
custom_fewshots_template: null

metainfo:
  basemodel_name: "your_run_name" # 実行名を適宜変更
  model_type: "open llm" # {open llm, commercial api} の中から選択
  instruction_tuning_method: "None" # {"None", "Full", "LoRA", ...}
  instruction_tuning_data: ["None"] # {"None", "jaster", "dolly_ja", "oasst_ja", ...}
  num_few_shots: 0
  llm-jp-eval-version: "1.1.0"

mtbench:
  question_artifacts_path: 'wandb-japan/llm-leaderboard/mtbench_ja_question:v0'
  referenceanswer_artifacts_path: 'wandb-japan/llm-leaderboard/mtbench_ja_referenceanswer:v0'
  judge_prompt_artifacts_path: 'wandb-japan/llm-leaderboard/mtbench_ja_prompt:v1'
  bench_name: 'japanese_mt_bench'
  model_id: 'your_unique_model_id'  # 一意なモデルIDを指定
  question_begin: null
  question_end: null
  max_new_token: 1024
  num_choices: 1
  num_gpus_per_model: 2
  num_gpus_total: 2
  max_gpu_memory: null
  dtype: bfloat16
  judge_model: 'gpt-4o-mini'
  mode: 'single'  # 'single' または 'pair'
  baseline_model: null
  parallel: 1
  first_n: null
  custom_conv_template: true
  conv_name: "custom"
  conv_system_template: "{system_message}"
  conv_system_message: "以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。"
  conv_roles: "('指示', '応答')"
  conv_sep: "\n\n### "
  conv_sep2: ""
  conv_stop_token_ids: "[2]"
  conv_stop_str: "###"
  conv_sep_style: "custom"
  conv_role_message_separator: ":\n"
  conv_role_only_separator: ":\n"
